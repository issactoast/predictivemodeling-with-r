---
title: "LightGBM model with Tidymodels"
author: "슬기로운통계생활"
date: "4/15/2021"
output: html_document
---

# 준비작업

## 패키지 불러오기

이번 포스팅에서 사용할 R패키지들을 불러오자. 특히 요즘 핫하디 핫한 `tidymodels` 사용하여 월마트 대회를 가지고 놀아본다. 또한 마이 빼이보릿 연산자들을 사용하기 위하여 `magrittr`를 불러왔다.🤣

```{r}
suppressMessages(library(magrittr))
suppressMessages(library(tidymodels)) %>% suppressWarnings()
suppressMessages(library(tidyverse)) %>% suppressWarnings()
suppressMessages(library(treesnip)) %>% suppressWarnings()
suppressMessages(library(skimr)) %>% suppressWarnings()
suppressMessages(library(knitr)) %>% suppressWarnings()
theme_set(theme_bw())
```

## 데이터셋 불러오기

이 대회에서 주어진 데이터셋을 불러보자. 주어진 파일 리스트는 다음과 같다.

```{r}
file_path <- "../input/daconcredit14/"
files <- list.files(file_path)
files
```
각 변수의 이름을 `janitor` 패키지로 말끔하게 바꿔준다.

```{r}
train <- read_csv(file.path(file_path, "train.csv")) %T>% 
  suppressMessages() %>% 
  janitor::clean_names()
test <- read_csv(file.path(file_path, "test.csv")) %T>%
  suppressMessages() %>% 
  janitor::clean_names()
```


# 데이터 기본정보 확인

```{r}
train %>% 
  head() %>% 
  kable() %>% 
  kableExtra::kable_styling("striped") %>% 
  kableExtra::scroll_box(width = "100%")
```

## 기본 정보

이 대회는 기본적으로 간단한 대회이다. 첫번째 스터디용 대회로 선택을 한 이유이기도 하다. 주 데이터는 2만 6천개의 train 표본과 1만개의 test 표본들로 구성이 되어있다.

```{r}
dim(train)
dim(test)
```

각 데이터 셋의 변수명을 살펴보자. 

```{r}
names(train)
names(test)
```

먼저 `test` 데이터에는 우리가 예측하고 싶은 변수인 `credit` 변수가 들어있지 않은 것을 알 수 있다. 

데이터를 훑어보기 위해서 `skim()` 함수를 이용하자. 이 함수는 데이터에 들어있는 변수들을 타입 별로 분석해서 리포트를 작성해준다.

```{r}
skim(train)
```

결과를 살펴보자. 먼저 결측치가 상대적으로 많이 없는 착한? 데이터이다. character 변수의 complete rate를 살펴보면 모든 변수가 1이고, `occyp_type` 변수만이 결측치가 8171개가 존재하는 것을 알 수 있다. 또한 고맙게도 numeric 변수의 결측치는 하나도 없다!😆

같은 함수를 사용해서 `test` 셋을 보면 똑같은 패턴을 가지고 있는 것을 알 수 있다.

```{r}
skim(test)
```

# 시각화

베이스 라인을 잡은 문서이니 간단하게 시각화 하나만 하고 넘어가자. (코드를 응용해서 다른 변수에 대한 상관 관계를 볼 수 있을 것이다.)

```{r}
train %>%
  ggplot(aes(x = factor(credit), y = income_total)) +
  geom_boxplot() +
  facet_grid(. ~ income_type)
```

# 전처리 하기

`tidymodels`에서는 전처리를 할 때 `recipe` 라는 패키지를 사용한다. 이 패키지에는 전처리를 하는 방법을 음식 레피시 처럼 적어놓는다고 생각하면 쉽다.

## all_data 묶기

앞으로 전처리를 할 때 좀 더 편리하게 하기 위해서 `all_data`로 묶어내도록 하자.

```{r}
all_data <- bind_rows(train, test)
all_data %>% dim()
```

## factor 변수로 바꿔주기

결과값인 credit 변수와 character 타입의 변수들을 factor 변수로 바꿔주자.

```{r}
all_data %<>%
  mutate_if(is.character, as.factor) %>% 
  mutate(credit = factor(credit))

all_data
```

## `recipe`를 통한 전처리 입력

```{r}
credit_recipe <- all_data %>% 
  recipe(credit ~ .) %>% 
  step_mutate(yrs_birth = -ceiling(days_birth/365),
              yrs_employed = -ceiling(days_employed/356)) %>% 
  step_rm(index, days_birth, days_employed) %>%
  step_unknown(occyp_type) %>% 
  step_integer(all_nominal(), -all_outcomes()) %>% 
  step_center(all_predictors(), -all_outcomes()) %>% 
  prep(training = all_data)

print(credit_recipe)
```

## `juice`를 통한 전처리 즙짜기

`juice()` 함수를 통해서 recipe에 입력된 전처리를 짜낸 데이터를 얻어온다.

```{r}
all_data2 <- juice(credit_recipe)
head(all_data2)
```

다음과 같이 결측치 없이 잘 코딩된 데이터를 얻었다는 것을 확인 할 수 있다.

```{r}
all_data2 %>%
map_df(~sum(is.na(.))) %>%
  pivot_longer(cols = everything(),
       names_to = "variable",
       values_to = "na_count") %>% 
  filter(na_count > 0)
```

전처리가 끝났으므로, train과 test셋을 나눈다.

```{r}
train_index <- seq_len(nrow(train))
train2 <- all_data2[train_index,]
test2 <- all_data2[-train_index,]
```

# 튜닝 준비하기

`validation_split()` 함수를 사용하여 평가셋을 분리한다. 한 단계 더 나아간 cross validation은 `vfold_cv()`함수에서 제공하니 찾아보도록 하자.

```{r}
set.seed(2021)

validation_split <- validation_split(train2, prop = 0.7,
                                     strata = credit)
```

## 튜닝 스펙 설정

```{r}
# https://support.microsoft.com/en-us/windows/find-out-how-many-cores-your-processor-has-3126ef99-0247-33b3-81fc-065e9fb0c35b
tune_spec <- boost_tree(
    trees = 16000,
    tree_depth = 8,
    min_n = 15,
    mtry = 5,
    sample_size = 0.3,
    learn_rate = 0.005,
    stop_iter = 10
) %>% 
    set_engine('xgboost', 
               # objective = "multi:softprob",
               verbose = 2, # print all
               nthread = 10) %>% 
    set_mode('classification')

workflow <- workflow() %>%
  add_model(tune_spec) %>% 
  add_formula(credit ~ .)

# Manual Tunning
library(tictoc)
tic()
set.seed(2021)
tune_result <- workflow %>% 
  tune_grid(validation_split,
            metrics = metric_set(mn_log_loss, accuracy))
toc()

tune_result %>% 
  collect_metrics()
# 0.6974546
# 0.7628974
```

```{r}
tune_result %>% show_best()
```

# 모델 확정

```{r}
tune_best <- tune_result %>% select_best(metric = "mn_log_loss")
final_spec <- finalize_model(tune_spec, tune_best)
final_spec
# Boosted Tree Model Specification (classification)
# 
# Main Arguments:
#   mtry = 9
#   trees = 1000
#   min_n = 3
#   tree_depth = 12
#   learn_rate = 0.012945107
#   loss_reduction = 8.71807395454724e-07
#   sample_size = 0.377971
# 
# Engine-Specific Arguments:
#   objective = multi:softprob
# 
# Computational engine: xgboost 
```

# 워크플로우 업데이트 및 마지막 학습

```{r}
workflow %<>% update_model(final_spec)
xgb_fit <- fit(workflow, data = train2)
```

# 예측하기

```{r warning=FALSE}
result <- predict(xgb_fit, test2, type = "prob")
result %>% head()
result
```

```{r, message=FALSE}
submission <- read_csv(file.path(file_path, "sample_submission.csv"))
sub_col <- names(submission)
submission <- bind_cols(submission$index, result)
names(submission) <- sub_col
write.csv(submission, row.names = FALSE,
          "baseline_dacon_credit_xgb.csv")
```

